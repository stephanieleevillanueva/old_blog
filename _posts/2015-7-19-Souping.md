---
layout: post
title: "Week 2: A Different Kind of Soup!"
published: false
---

Last week in class, we were introduced to this thing called ``BeautifulSoup``. And no... we're not talking about the hot, succulent liquid dish you indulge in at restaurants or those packaged goods you get from groceries, though it would be quite tempting to blog about where to get the best chowders or pumpkin soup in the country. I guess I will just have to save that blog for another day. :)

If you are a new Python programmer like me, chances are you'd run into ``BeautifulSoup`` when you get to do web scraping. I have tried looking into the origin of its name but no luck so far in my search so for now, we'll focus on what``BeautifulSoup`` is and what it does.

``BeautifulSoup`` is a Python library for parsing HTML and XML documents. It creates parse trees and does the tree traversal for you as well. It helps users extract data from HTML quickly using various built-in methods. In short, it is a very handy tool for doing fast and efficient web scraping.

In this blog I will cover the basic steps in web scraping using ``BeautifulSoup``. I will put out a few code snippets along the way to help understand and demonstrate how this library is used. 

**Web Scraping Demo**
======


First, you have to install the package by opening your terminal or command line and typing ``pip install beautifulsoup4``. The version of ``BeautifulSoup`` may change, depending on the current release. As of publishing this blog, we are at version 4. To be able to use ``BeautifulSoup``, you need to import and run the package. 


And now to the good stuff! I will be using content from www.tvseriesfinale.com for this blog, which is also the data I used in my project at Metis. This write-up is actually part one of my two-part blog on regression analysis of data pulled from the web. ``requests.get()`` just means get server response, ``.text`` as text and we store this in the variable ``page``. Now we are ready to parse the html document using ``BeautifulSoup``.
