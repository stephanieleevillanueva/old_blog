---
layout: post
title: "Week 2: A Different Kind of Soup!"
published: false
---

Last week in class, we were introduced to this thing called ``BeautifulSoup``. And no... we're not talking about the hot, succulent liquid dish you indulge in at restaurants or those packaged goods you get from groceries, though it would be quite tempting to blog about where to get the best chowders or pumpkin soup in the country. I guess I will just have to save that blog for another day. :)

If you are a new Python programmer like me, chances are you'd run into ``BeautifulSoup`` when you get to do web scraping. I have tried looking into the origin of its name but no luck so far in my search so for now, we'll focus on what``BeautifulSoup`` is and what it does.

``BeautifulSoup`` is a Python library for parsing HTML and XML documents. It creates parse trees and does the tree traversal for you as well. It helps users extract data from HTML quickly using various built-in methods. In short, it is a very handy tool for doing fast and efficient web scraping.

In this blog I will cover the basic steps in web scraping using ``BeautifulSoup``. I will put out a few code snippets along the way to help understand and demonstrate how this library is used. 

**Web Scraping Demo**
======
![_config.yml](https://raw.githubusercontent.com/stephanieleevillanueva/stephanieleevillanueva.github.io/master/images/Week_2/imports.png)

First, you have to install the package by opening your terminal or command line and typing ``pip install beautifulsoup4``. The version of ``BeautifulSoup`` may change, depending on the current release. As of publishing this blog, we are at version 4. To be able to use ``BeautifulSoup``, you need to import and run the package. 

![_config.yml](https://raw.githubusercontent.com/stephanieleevillanueva/stephanieleevillanueva.github.io/master/images/Week_2/soup.png)

And now to the good stuff! I will be using content from www.tvseriesfinale.com for this blog, which is also the data I used in my project at Metis. This write-up is actually part one of my two-part blog on regression analysis of data pulled from the web. ``requests.get()`` just means get server response, ``.text`` as text and we store this in the variable ``page``. Now we are ready to parse the html document using ``BeautifulSoup``.

To create a soup object, just instantiate ``BeautifulSoup`` with html document as parameter.

![_config.yml](https://raw.githubusercontent.com/stephanieleevillanueva/stephanieleevillanueva.github.io/master/images/Week_2/prettify.png)

``BeautifulSoup`` has a function called ``prettify()`` that basically shows the html tags in a structured way. This is helpful to easily see which part of the tree to start traversing.

When I did web scraping for my dataset, I found that even just by using only the most common functions I was already able to get the data I needed. For this reason, I will limit my discussion to the functions I used. Feel free to explore more functions through ``BeautifulSoup``'s documentation http://www.crummy.com/software/BeautifulSoup/bs4/doc/.

![_config.yml](https://raw.githubusercontent.com/stephanieleevillanueva/stephanieleevillanueva.github.io/master/images/Week_2/code.png)

Let's do a breakdown of this code.

Probably the most useful and handy function in this library is ``find()`` (for a single instance) or ``find_all()`` (for all instances). 

![_config.yml](https://raw.githubusercontent.com/stephanieleevillanueva/stephanieleevillanueva.github.io/master/images/Week_2/find.png)

``find()`` returns a tag element with contents after the found tag or text. 

![_config.yml](https://raw.githubusercontent.com/stephanieleevillanueva/stephanieleevillanueva.github.io/master/images/Week_2/find_all.png)

``find_all()``, on the other hand, returns a resultset similar to Python lists.

![_config.yml](https://raw.githubusercontent.com/stephanieleevillanueva/stephanieleevillanueva.github.io/master/images/Week_2/functions.png)

Now ``.text`` returns all texts found inside the tag parameter in ``find()``. And a tag's (in this case <p>) children can be accessed using the ``.contents`` function.

What is returned is a list of just the data I need (show title and network) from the original soup page at the beginning of this write-up. 

There we go! A brief introduction to ``BeautifulSoup`` and how powerful a tool it is. By using even its most basic functions, you can already go a long way in terms of web scraping. 
